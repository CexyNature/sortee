Manuscrito original [[1]](#1)

## Hacia una ecología y una biología evolutiva abiertas, fiables y transparentes

Autores:

> O’Dea RE, Parker TH, Chee YE, Culina A, Drobniak SM, Duncan DH, Fidler F, Gould E, Ihle M, Kelly CD, Lagisz M.

Resumen:

> Los programas de investigación poco confiables desperdician fondos, tiempo e incluso la vida de los organismos que buscamos ayudar y comprender. Reducir este desperdicio y aumentar el valor de la evidencia científica requiere cambiar las acciones tanto de los investigadores individuales como de las instituciones que los emplean y definen sus políticas de promoción. Si bien los ecólogos y los biólogos evolutivos han mejorado un poco la transparencia de la investigación durante la última década (por ejemplo, más intercambio de datos), aún quedan obstáculos importantes. En este comentario, miramos al futuro e imaginamos cómo los investigadores y las instituciones pueden allanar el camino hacia programas de investigación más creíbles y eficaces.


Leyenda figura 1:

> El investigador fatigado es apartado de sus ideales por los incentivos de las instituciones de las que depende para el empleo y la promoción. Las prácticas y comportamientos en el lado izquierdo del juego de tirar y aflojar la cuerda (sombreado en naranja) representan problemas del statu quo, donde la investigación se enfoca más en publicar artículos que en responder preguntas. Las prácticas y comportamientos preferidos en el lado derecho del juego de tirar y aflojar la cuerda (sombreado en azul) representan una visión de ciencia eficiente y colaborativa destinada a responder preguntas de manera creíble. Para cambiar las prácticas de investigación hacia la confiabilidad, podrían cambiar tres tipos de incentivos institucionales, como se muestra en los recuadros grises debajo del juego de tirar y aflojar la cuerda. En primer lugar, las revistas y los financiadores podrían alentar rápidamente la validación de la investigación original mediante la publicación y la financiación de estudios de replicación. Es menos probable que las revistas publiquen menos programas de investigación, más completos y coherentes (tanto estudios a largo plazo como colecciones de estudios más pequeños sobre el mismo tema de investigación), aliviando así las presiones para exagerar la importancia de los estudios pequeños. En segundo lugar, los empleadores podrían contratar a personas con experiencia especializada (por ejemplo, administradores de datos, empiristas, estadísticos y escritores), cuyo empleo no dependa de resultados de investigación particulares. Reducir la estructura piramidal de las trayectorias profesionales académicas podría promover una fuerza laboral más diversa que, sin la presión de mantener marcas profesionales, podría descartar más rápido las creencias desacreditadas. En tercer lugar, las agencias de financiación podrían frenar los beneficios de la autopromoción y los resultados irreproducibles mediante la financiación de equipos diversos, el mantenimiento de la ciencia (por ejemplo, validación y detección de errores) tanto como la innovación, y mediante la selección aleatoria de proyectos que superan determinados umbrales (es decir, loterías de subvenciones). Las loterías de subvenciones ya están siendo probadas por múltiples agencias de financiación (por ejemplo, el Fondo Fetzer Franklin, el Consejo de Investigación de la Salud de Nueva Zelanda y la Fundación Nacional de Ciencias de Suiza), pero sus efectos en la confiabilidad de la investigación dependerán de qué métricas se utilicen para seleccionar participantes en la lotería.

Leyenda figure 2

> Tres áreas de reforma para aliviar la tensión de la investigación, preguntas pendientes para la meta-investigación y posibles respuestas. Detección de errores: los investigadores deben poder distinguir entre investigaciones confiables y no confiables. Un mejor sistema de control de calidad (tanto antes como después de la publicación) podría desalentar las prácticas de investigación que inflan la tasa de hallazgos falsos positivos en la literatura de investigación (por ejemplo, informes selectivos, p-hacking, HARKing). Al mismo tiempo, debe haber incentivos para que los investigadores corrijan errores en su trabajo anterior, por ejemplo, a través de documentos "vivos" que puedan actualizarse fácilmente. Un cambio más drástico sería exigir que se repliquen los estudios independientes y que los resultados publicados de los estudios de campo a largo plazo se revisen en los años siguientes (por ejemplo, antes de que se renueve la financiación). Desarrollo de la teoría: la investigación en ecología y biología evolutiva a veces no logra atravesar el espacio entre la especulación y la teoría. Además de la prueba de hipótesis, responder preguntas importantes requiere espacio para la investigación descriptiva y exploratoria [[2]](#2). Las descripciones detalladas de la historia natural ayudan a calibrar los modelos teóricos, y las predicciones de los modelos deben probarse en entornos naturales. Para especificar las condiciones bajo las cuales se espera que los hallazgos se repliquen, los autores pueden incluir declaraciones de "restricciones en la generalidad" junto con las inferencias. Cuando los resultados inesperados se atribuyen a la "dependencia del contexto", los contextos específicos se pueden probar con nuevos datos. Para la investigación acumulativa, los estudios fundamentales pueden validarse con réplicas cercanas y su generalidad puede evaluarse en diferentes entornos. Recursos humanos: los programas de educación podrían aumentar la capacidad de los investigadores para trabajar de manera transparente y reproducible, pero perfeccionar estas habilidades y realizar investigaciones rigurosas con demasiada frecuencia no es recompensado. Cualquier cambio en las métricas de evaluación requiere una consideración cuidadosa y la medición de las consecuencias no deseadas (por ejemplo, cómo garantizar que los costos no sean asumidos de manera desproporcionada por grupos de investigación y universidades con menos recursos). Gran parte de la investigación publicada representa proyectos independientes llevados a cabo por aprendices, pero se puede aumentar la confiabilidad coordinando a varios aprendices en los mismos proyectos (incluidos los proyectos de replicación) y brindando empleo seguro a personas con experiencia especializada (que pueden ser profesionalmente indiferentes al resultado de un estudio en particular).


<a id="1">[1]</a> 
[O’Dea RE, Parker TH, Chee YE, Culina A, Drobniak SM, Duncan DH, Fidler F, Gould E, Ihle M, Kelly CD, Lagisz M. (2021) Towards open, reliable, and transparent ecology and evolutionary biology. BMC biology 19(1):1-5.](https://doi.org/10.1186/s12915-021-01006-3)

<a id="2">[2]</a> 
Scheel AM, Tiokhin L, Isager PM, Lakens D. (2021) Why hypothesis testers should spend less time testing hypotheses. Perspectives on Psychological Science 16(4):744-55.